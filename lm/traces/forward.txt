rh:nlp$ java -cp ../ nlp.lm.BigramModel data/pos/atis/ 0.1
# Train Sentences = 519 (# words = 3922) 
# Test Sentences = 58 (# words = 431)
----------------------------------
Forward BigramModel
Training...
Perplexity = 9.043192013019798
Word Perplexity = 10.5919539986291
Testing...
Perplexity = 19.341388622483773
Word Perplexity = 24.053999598153656
----------------------------------

rh:nlp$ java -cp ../ nlp.lm.BigramModel data/pos/wsj/ 0.1
# Train Sentences = 43820 (# words = 996418) 
# Test Sentences = 4869 (# words = 110926)
----------------------------------
Forward BigramModel
Training...
Perplexity = 73.9483923189533
Word Perplexity = 88.47240730096729
Testing...
Perplexity = 234.07965011179772
Word Perplexity = 294.52021253256413
----------------------------------

rh:nlp$ java -cp ../ nlp.lm.BigramModel data/pos/brown/ 0.1
# Train Sentences = 47207 (# words = 1062447) 
# Test Sentences = 5245 (# words = 110523)
----------------------------------
Forward BigramModel
Training...
Perplexity = 90.98253155662894
Word Perplexity = 110.47387795072683
Testing...
Perplexity = 386.9621221186537
Word Perplexity = 509.6864163268459
----------------------------------
