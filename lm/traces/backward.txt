dots$ java -cp ../.. nlp.lm.BackwardBigramModel /projects/nlp/penn-treebank3/tagged/pos/atis/ 0.1
# Train Sentences = 519 (# words = 3922) 
# Test Sentences = 58 (# words = 431)
Training...
Perplexity = 9.043192013019798
Word Perplexity = 11.680443791554506
Testing...
Perplexity = 19.341388622483773
Word Perplexity = 27.124810818769507
dots$ java -cp ../.. nlp.lm.BackwardBigramModel /projects/nlp/penn-treebank3/tagged/pos/wsj/ 0.1
# Train Sentences = 43820 (# words = 995626) 
# Test Sentences = 4869 (# words = 111718)
Training...
Perplexity = 74.26799183241476
Word Perplexity = 86.65516421729026
Testing...
Perplexity = 219.71517777445175
Word Perplexity = 266.58242877788786
dots$ java -cp ../.. nlp.lm.BackwardBigramModel /projects/nlp/penn-treebank3/tagged/pos/brown/ 0.1
# Train Sentences = 47207 (# words = 1079440) 
# Test Sentences = 5245 (# words = 93530)
Training...
Perplexity = 93.51927720192262
Word Perplexity = 110.78196649093694
Testing...
Perplexity = 231.30243689356243
Word Perplexity = 299.82995708613305
